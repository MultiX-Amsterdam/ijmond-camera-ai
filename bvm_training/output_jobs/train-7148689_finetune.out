Generator Learning Rate: 2.5e-05
Length of dataset: 258
Dataset size: 37
Let's go!
Generator Learning Rate: 2.5e-05
2024-07-24 17:37:26.998380 Epoch [001/050], Step [0010/0037], Gen Loss: 0.9947
2024-07-24 17:37:28.942769 Epoch [001/050], Step [0020/0037], Gen Loss: 0.9214
2024-07-24 17:37:30.885937 Epoch [001/050], Step [0030/0037], Gen Loss: 0.8778
2024-07-24 17:37:32.636894 Epoch [001/050], Step [0037/0037], Gen Loss: 0.8567
Generator Learning Rate: 2.5e-05
2024-07-24 17:37:35.068632 Epoch [002/050], Step [0010/0037], Gen Loss: 0.8396
2024-07-24 17:37:37.029838 Epoch [002/050], Step [0020/0037], Gen Loss: 0.7664
2024-07-24 17:37:38.970999 Epoch [002/050], Step [0030/0037], Gen Loss: 0.7432
2024-07-24 17:37:40.333005 Epoch [002/050], Step [0037/0037], Gen Loss: 0.7287
Generator Learning Rate: 2.5e-05
2024-07-24 17:37:42.826339 Epoch [003/050], Step [0010/0037], Gen Loss: 0.6126
2024-07-24 17:37:44.818184 Epoch [003/050], Step [0020/0037], Gen Loss: 0.6079
2024-07-24 17:37:46.778981 Epoch [003/050], Step [0030/0037], Gen Loss: 0.6082
2024-07-24 17:37:48.145168 Epoch [003/050], Step [0037/0037], Gen Loss: 0.6020
Generator Learning Rate: 2.5e-05
2024-07-24 17:37:50.590872 Epoch [004/050], Step [0010/0037], Gen Loss: 0.5964
2024-07-24 17:37:52.539273 Epoch [004/050], Step [0020/0037], Gen Loss: 0.5973
2024-07-24 17:37:54.574207 Epoch [004/050], Step [0030/0037], Gen Loss: 0.5956
2024-07-24 17:37:55.934053 Epoch [004/050], Step [0037/0037], Gen Loss: 0.5961
Generator Learning Rate: 2.5e-05
2024-07-24 17:37:58.373350 Epoch [005/050], Step [0010/0037], Gen Loss: 0.5538
2024-07-24 17:38:00.335642 Epoch [005/050], Step [0020/0037], Gen Loss: 0.5337
2024-07-24 17:38:02.286488 Epoch [005/050], Step [0030/0037], Gen Loss: 0.5346
2024-07-24 17:38:03.645916 Epoch [005/050], Step [0037/0037], Gen Loss: 0.5460
Generator Learning Rate: 2.5e-05
2024-07-24 17:38:06.122211 Epoch [006/050], Step [0010/0037], Gen Loss: 0.6489
2024-07-24 17:38:08.080792 Epoch [006/050], Step [0020/0037], Gen Loss: 0.6224
2024-07-24 17:38:10.030815 Epoch [006/050], Step [0030/0037], Gen Loss: 0.6100
2024-07-24 17:38:11.393629 Epoch [006/050], Step [0037/0037], Gen Loss: 0.5982
Generator Learning Rate: 2.5e-05
2024-07-24 17:38:13.894942 Epoch [007/050], Step [0010/0037], Gen Loss: 0.5940
2024-07-24 17:38:15.864608 Epoch [007/050], Step [0020/0037], Gen Loss: 0.5664
2024-07-24 17:38:17.830104 Epoch [007/050], Step [0030/0037], Gen Loss: 0.5899
2024-07-24 17:38:19.198142 Epoch [007/050], Step [0037/0037], Gen Loss: 0.5965
Generator Learning Rate: 2.5e-05
2024-07-24 17:38:21.677561 Epoch [008/050], Step [0010/0037], Gen Loss: 0.7734
2024-07-24 17:38:23.640473 Epoch [008/050], Step [0020/0037], Gen Loss: 0.9884
2024-07-24 17:38:25.598519 Epoch [008/050], Step [0030/0037], Gen Loss: 0.9026
2024-07-24 17:38:26.970672 Epoch [008/050], Step [0037/0037], Gen Loss: 0.8781
Generator Learning Rate: 2.5e-05
2024-07-24 17:38:29.482585 Epoch [009/050], Step [0010/0037], Gen Loss: 0.9412
2024-07-24 17:38:31.434246 Epoch [009/050], Step [0020/0037], Gen Loss: 0.9393
2024-07-24 17:38:33.377296 Epoch [009/050], Step [0030/0037], Gen Loss: 0.9600
2024-07-24 17:38:34.926166 Epoch [009/050], Step [0037/0037], Gen Loss: 0.9496
Generator Learning Rate: 2.5e-05
2024-07-24 17:38:37.470897 Epoch [010/050], Step [0010/0037], Gen Loss: 0.5917
2024-07-24 17:38:39.427704 Epoch [010/050], Step [0020/0037], Gen Loss: 0.6111
2024-07-24 17:38:41.378316 Epoch [010/050], Step [0030/0037], Gen Loss: 0.5721
2024-07-24 17:38:42.741930 Epoch [010/050], Step [0037/0037], Gen Loss: 0.5488
Generator Learning Rate: 2.5e-05
2024-07-24 17:38:45.456757 Epoch [011/050], Step [0010/0037], Gen Loss: 0.4743
2024-07-24 17:38:47.412906 Epoch [011/050], Step [0020/0037], Gen Loss: 0.4774
2024-07-24 17:38:49.363708 Epoch [011/050], Step [0030/0037], Gen Loss: 0.4671
2024-07-24 17:38:50.721834 Epoch [011/050], Step [0037/0037], Gen Loss: 0.4662
Generator Learning Rate: 2.5e-05
2024-07-24 17:38:53.158507 Epoch [012/050], Step [0010/0037], Gen Loss: 0.4305
2024-07-24 17:38:55.116626 Epoch [012/050], Step [0020/0037], Gen Loss: 0.4176
2024-07-24 17:38:57.068279 Epoch [012/050], Step [0030/0037], Gen Loss: 0.4241
2024-07-24 17:38:58.428647 Epoch [012/050], Step [0037/0037], Gen Loss: 0.4206
Generator Learning Rate: 2.5e-05
2024-07-24 17:39:00.906286 Epoch [013/050], Step [0010/0037], Gen Loss: 0.4470
2024-07-24 17:39:02.864353 Epoch [013/050], Step [0020/0037], Gen Loss: 0.4586
2024-07-24 17:39:04.814811 Epoch [013/050], Step [0030/0037], Gen Loss: 0.4697
2024-07-24 17:39:06.177445 Epoch [013/050], Step [0037/0037], Gen Loss: 0.4784
Generator Learning Rate: 2.5e-05
2024-07-24 17:39:08.628039 Epoch [014/050], Step [0010/0037], Gen Loss: 0.4355
2024-07-24 17:39:10.573566 Epoch [014/050], Step [0020/0037], Gen Loss: 0.4551
2024-07-24 17:39:12.515392 Epoch [014/050], Step [0030/0037], Gen Loss: 0.4792
2024-07-24 17:39:13.866170 Epoch [014/050], Step [0037/0037], Gen Loss: 0.4676
Generator Learning Rate: 2.5e-05
2024-07-24 17:39:16.401002 Epoch [015/050], Step [0010/0037], Gen Loss: 0.5010
2024-07-24 17:39:18.364022 Epoch [015/050], Step [0020/0037], Gen Loss: 0.4668
2024-07-24 17:39:20.320956 Epoch [015/050], Step [0030/0037], Gen Loss: 0.5202
2024-07-24 17:39:21.681518 Epoch [015/050], Step [0037/0037], Gen Loss: 0.6327
Generator Learning Rate: 2.5e-05
2024-07-24 17:39:24.114297 Epoch [016/050], Step [0010/0037], Gen Loss: 0.5945
2024-07-24 17:39:26.063387 Epoch [016/050], Step [0020/0037], Gen Loss: 0.5987
2024-07-24 17:39:28.015752 Epoch [016/050], Step [0030/0037], Gen Loss: 0.6976
2024-07-24 17:39:29.375248 Epoch [016/050], Step [0037/0037], Gen Loss: 1.4903
Generator Learning Rate: 2.5e-05
2024-07-24 17:39:31.854121 Epoch [017/050], Step [0010/0037], Gen Loss: 4.4773
2024-07-24 17:39:33.808888 Epoch [017/050], Step [0020/0037], Gen Loss: 3.9361
2024-07-24 17:39:35.772663 Epoch [017/050], Step [0030/0037], Gen Loss: 3.8187
2024-07-24 17:39:37.138529 Epoch [017/050], Step [0037/0037], Gen Loss: 3.4271
Generator Learning Rate: 2.5e-05
2024-07-24 17:39:39.698316 Epoch [018/050], Step [0010/0037], Gen Loss: 1.4115
2024-07-24 17:39:41.656044 Epoch [018/050], Step [0020/0037], Gen Loss: 1.2855
2024-07-24 17:39:43.610241 Epoch [018/050], Step [0030/0037], Gen Loss: 1.1971
2024-07-24 17:39:44.968646 Epoch [018/050], Step [0037/0037], Gen Loss: 1.1278
Generator Learning Rate: 2.5e-05
2024-07-24 17:39:47.483721 Epoch [019/050], Step [0010/0037], Gen Loss: 0.9973
2024-07-24 17:39:49.443705 Epoch [019/050], Step [0020/0037], Gen Loss: 0.8535
2024-07-24 17:39:51.393875 Epoch [019/050], Step [0030/0037], Gen Loss: 0.7959
2024-07-24 17:39:52.746604 Epoch [019/050], Step [0037/0037], Gen Loss: 0.7860
Generator Learning Rate: 2.5e-06
2024-07-24 17:39:55.193203 Epoch [020/050], Step [0010/0037], Gen Loss: 0.6538
2024-07-24 17:39:57.223255 Epoch [020/050], Step [0020/0037], Gen Loss: 0.5888
2024-07-24 17:39:59.173379 Epoch [020/050], Step [0030/0037], Gen Loss: 0.5672
2024-07-24 17:40:00.530267 Epoch [020/050], Step [0037/0037], Gen Loss: 0.5403
Generator Learning Rate: 2.5e-06
2024-07-24 17:40:03.276679 Epoch [021/050], Step [0010/0037], Gen Loss: 0.4761
2024-07-24 17:40:05.234117 Epoch [021/050], Step [0020/0037], Gen Loss: 0.4528
2024-07-24 17:40:07.188274 Epoch [021/050], Step [0030/0037], Gen Loss: 0.4606
2024-07-24 17:40:08.547871 Epoch [021/050], Step [0037/0037], Gen Loss: 0.4519
Generator Learning Rate: 2.5e-06
2024-07-24 17:40:11.013761 Epoch [022/050], Step [0010/0037], Gen Loss: 0.4330
2024-07-24 17:40:12.975456 Epoch [022/050], Step [0020/0037], Gen Loss: 0.4446
2024-07-24 17:40:14.930954 Epoch [022/050], Step [0030/0037], Gen Loss: 0.4453
2024-07-24 17:40:16.292416 Epoch [022/050], Step [0037/0037], Gen Loss: 0.4527
Generator Learning Rate: 2.5e-06
2024-07-24 17:40:18.797621 Epoch [023/050], Step [0010/0037], Gen Loss: 0.4149
2024-07-24 17:40:20.761919 Epoch [023/050], Step [0020/0037], Gen Loss: 0.4219
2024-07-24 17:40:22.719294 Epoch [023/050], Step [0030/0037], Gen Loss: 0.4162
2024-07-24 17:40:24.082090 Epoch [023/050], Step [0037/0037], Gen Loss: 0.4167
Generator Learning Rate: 2.5e-06
2024-07-24 17:40:26.543317 Epoch [024/050], Step [0010/0037], Gen Loss: 0.4122
2024-07-24 17:40:28.494692 Epoch [024/050], Step [0020/0037], Gen Loss: 0.4280
2024-07-24 17:40:30.441523 Epoch [024/050], Step [0030/0037], Gen Loss: 0.4281
2024-07-24 17:40:31.793331 Epoch [024/050], Step [0037/0037], Gen Loss: 0.4358
Generator Learning Rate: 2.5e-06
2024-07-24 17:40:34.233730 Epoch [025/050], Step [0010/0037], Gen Loss: 0.4618
2024-07-24 17:40:36.179953 Epoch [025/050], Step [0020/0037], Gen Loss: 0.4443
2024-07-24 17:40:38.212751 Epoch [025/050], Step [0030/0037], Gen Loss: 0.4461
2024-07-24 17:40:39.569610 Epoch [025/050], Step [0037/0037], Gen Loss: 0.4508
Generator Learning Rate: 2.5e-06
2024-07-24 17:40:42.129673 Epoch [026/050], Step [0010/0037], Gen Loss: 0.4124
2024-07-24 17:40:44.084297 Epoch [026/050], Step [0020/0037], Gen Loss: 0.4052
2024-07-24 17:40:46.032888 Epoch [026/050], Step [0030/0037], Gen Loss: 0.4075
2024-07-24 17:40:47.389718 Epoch [026/050], Step [0037/0037], Gen Loss: 0.4061
Generator Learning Rate: 2.5e-06
2024-07-24 17:40:49.867367 Epoch [027/050], Step [0010/0037], Gen Loss: 0.4036
2024-07-24 17:40:51.822116 Epoch [027/050], Step [0020/0037], Gen Loss: 0.3985
2024-07-24 17:40:53.769811 Epoch [027/050], Step [0030/0037], Gen Loss: 0.3971
2024-07-24 17:40:55.127556 Epoch [027/050], Step [0037/0037], Gen Loss: 0.4161
Generator Learning Rate: 2.5e-06
2024-07-24 17:40:57.624932 Epoch [028/050], Step [0010/0037], Gen Loss: 0.3897
2024-07-24 17:40:59.586495 Epoch [028/050], Step [0020/0037], Gen Loss: 0.3815
2024-07-24 17:41:01.542074 Epoch [028/050], Step [0030/0037], Gen Loss: 0.3891
2024-07-24 17:41:02.907527 Epoch [028/050], Step [0037/0037], Gen Loss: 0.4036
Generator Learning Rate: 2.5e-06
2024-07-24 17:41:05.352523 Epoch [029/050], Step [0010/0037], Gen Loss: 0.4293
2024-07-24 17:41:07.308614 Epoch [029/050], Step [0020/0037], Gen Loss: 0.4184
2024-07-24 17:41:09.256140 Epoch [029/050], Step [0030/0037], Gen Loss: 0.4118
2024-07-24 17:41:10.613354 Epoch [029/050], Step [0037/0037], Gen Loss: 0.4126
Generator Learning Rate: 2.5e-06
2024-07-24 17:41:13.069924 Epoch [030/050], Step [0010/0037], Gen Loss: 0.4226
2024-07-24 17:41:15.015806 Epoch [030/050], Step [0020/0037], Gen Loss: 0.4142
2024-07-24 17:41:16.954348 Epoch [030/050], Step [0030/0037], Gen Loss: 0.4190
2024-07-24 17:41:18.394535 Epoch [030/050], Step [0037/0037], Gen Loss: 0.4153
Generator Learning Rate: 2.5e-06
2024-07-24 17:41:21.104697 Epoch [031/050], Step [0010/0037], Gen Loss: 0.3823
2024-07-24 17:41:23.064294 Epoch [031/050], Step [0020/0037], Gen Loss: 0.3992
2024-07-24 17:41:25.019241 Epoch [031/050], Step [0030/0037], Gen Loss: 0.4012
2024-07-24 17:41:26.379806 Epoch [031/050], Step [0037/0037], Gen Loss: 0.3895
Generator Learning Rate: 2.5e-06
2024-07-24 17:41:28.858445 Epoch [032/050], Step [0010/0037], Gen Loss: 0.3865
2024-07-24 17:41:30.820752 Epoch [032/050], Step [0020/0037], Gen Loss: 0.3905
2024-07-24 17:41:32.782714 Epoch [032/050], Step [0030/0037], Gen Loss: 0.3940
2024-07-24 17:41:34.151589 Epoch [032/050], Step [0037/0037], Gen Loss: 0.3932
Generator Learning Rate: 2.5e-06
2024-07-24 17:41:36.621193 Epoch [033/050], Step [0010/0037], Gen Loss: 0.3713
2024-07-24 17:41:38.578190 Epoch [033/050], Step [0020/0037], Gen Loss: 0.3807
2024-07-24 17:41:40.538224 Epoch [033/050], Step [0030/0037], Gen Loss: 0.3845
2024-07-24 17:41:41.901652 Epoch [033/050], Step [0037/0037], Gen Loss: 0.3827
Generator Learning Rate: 2.5e-06
2024-07-24 17:41:44.389176 Epoch [034/050], Step [0010/0037], Gen Loss: 0.4011
2024-07-24 17:41:46.446728 Epoch [034/050], Step [0020/0037], Gen Loss: 0.3851
2024-07-24 17:41:48.413082 Epoch [034/050], Step [0030/0037], Gen Loss: 0.3858
2024-07-24 17:41:49.783974 Epoch [034/050], Step [0037/0037], Gen Loss: 0.3875
Generator Learning Rate: 2.5e-06
2024-07-24 17:41:52.260026 Epoch [035/050], Step [0010/0037], Gen Loss: 0.3933
2024-07-24 17:41:54.207062 Epoch [035/050], Step [0020/0037], Gen Loss: 0.3829
2024-07-24 17:41:56.145963 Epoch [035/050], Step [0030/0037], Gen Loss: 0.3763
2024-07-24 17:41:57.513414 Epoch [035/050], Step [0037/0037], Gen Loss: 0.3882
Generator Learning Rate: 2.5e-06
2024-07-24 17:42:00.169548 Epoch [036/050], Step [0010/0037], Gen Loss: 0.3899
2024-07-24 17:42:02.128440 Epoch [036/050], Step [0020/0037], Gen Loss: 0.3794
2024-07-24 17:42:04.082569 Epoch [036/050], Step [0030/0037], Gen Loss: 0.3848
2024-07-24 17:42:05.443976 Epoch [036/050], Step [0037/0037], Gen Loss: 0.3791
Generator Learning Rate: 2.5e-06
2024-07-24 17:42:07.911503 Epoch [037/050], Step [0010/0037], Gen Loss: 0.3945
2024-07-24 17:42:09.866643 Epoch [037/050], Step [0020/0037], Gen Loss: 0.3822
2024-07-24 17:42:11.821596 Epoch [037/050], Step [0030/0037], Gen Loss: 0.3863
2024-07-24 17:42:13.185260 Epoch [037/050], Step [0037/0037], Gen Loss: 0.3858
Generator Learning Rate: 2.5e-06
2024-07-24 17:42:15.647781 Epoch [038/050], Step [0010/0037], Gen Loss: 0.3768
2024-07-24 17:42:17.607185 Epoch [038/050], Step [0020/0037], Gen Loss: 0.3891
2024-07-24 17:42:19.561848 Epoch [038/050], Step [0030/0037], Gen Loss: 0.3840
2024-07-24 17:42:20.922617 Epoch [038/050], Step [0037/0037], Gen Loss: 0.3860
Generator Learning Rate: 2.5e-06
2024-07-24 17:42:23.414902 Epoch [039/050], Step [0010/0037], Gen Loss: 0.3838
2024-07-24 17:42:25.375619 Epoch [039/050], Step [0020/0037], Gen Loss: 0.3843
2024-07-24 17:42:27.334065 Epoch [039/050], Step [0030/0037], Gen Loss: 0.3777
2024-07-24 17:42:28.696815 Epoch [039/050], Step [0037/0037], Gen Loss: 0.3736
Generator Learning Rate: 2.5000000000000004e-07
2024-07-24 17:42:31.149221 Epoch [040/050], Step [0010/0037], Gen Loss: 0.3853
2024-07-24 17:42:33.096425 Epoch [040/050], Step [0020/0037], Gen Loss: 0.3730
2024-07-24 17:42:35.034070 Epoch [040/050], Step [0030/0037], Gen Loss: 0.3731
2024-07-24 17:42:36.384998 Epoch [040/050], Step [0037/0037], Gen Loss: 0.3744
Generator Learning Rate: 2.5000000000000004e-07
2024-07-24 17:42:39.234697 Epoch [041/050], Step [0010/0037], Gen Loss: 0.3434
2024-07-24 17:42:41.203777 Epoch [041/050], Step [0020/0037], Gen Loss: 0.3727
2024-07-24 17:42:43.173465 Epoch [041/050], Step [0030/0037], Gen Loss: 0.3627
2024-07-24 17:42:44.537612 Epoch [041/050], Step [0037/0037], Gen Loss: 0.3631
Generator Learning Rate: 2.5000000000000004e-07
2024-07-24 17:42:47.038576 Epoch [042/050], Step [0010/0037], Gen Loss: 0.3485
2024-07-24 17:42:49.001970 Epoch [042/050], Step [0020/0037], Gen Loss: 0.3518
2024-07-24 17:42:50.957637 Epoch [042/050], Step [0030/0037], Gen Loss: 0.3526
2024-07-24 17:42:52.386917 Epoch [042/050], Step [0037/0037], Gen Loss: 0.3505
Generator Learning Rate: 2.5000000000000004e-07
2024-07-24 17:42:54.829478 Epoch [043/050], Step [0010/0037], Gen Loss: 0.3638
2024-07-24 17:42:56.787721 Epoch [043/050], Step [0020/0037], Gen Loss: 0.3749
2024-07-24 17:42:58.747857 Epoch [043/050], Step [0030/0037], Gen Loss: 0.3730
2024-07-24 17:43:00.110987 Epoch [043/050], Step [0037/0037], Gen Loss: 0.3765
Generator Learning Rate: 2.5000000000000004e-07
2024-07-24 17:43:02.569944 Epoch [044/050], Step [0010/0037], Gen Loss: 0.3924
2024-07-24 17:43:04.526502 Epoch [044/050], Step [0020/0037], Gen Loss: 0.3808
2024-07-24 17:43:06.475853 Epoch [044/050], Step [0030/0037], Gen Loss: 0.3801
2024-07-24 17:43:07.832419 Epoch [044/050], Step [0037/0037], Gen Loss: 0.3747
Generator Learning Rate: 2.5000000000000004e-07
2024-07-24 17:43:10.285154 Epoch [045/050], Step [0010/0037], Gen Loss: 0.3397
2024-07-24 17:43:12.248834 Epoch [045/050], Step [0020/0037], Gen Loss: 0.3515
2024-07-24 17:43:14.190482 Epoch [045/050], Step [0030/0037], Gen Loss: 0.3515
2024-07-24 17:43:15.545196 Epoch [045/050], Step [0037/0037], Gen Loss: 0.3557
Generator Learning Rate: 2.5000000000000004e-07
2024-07-24 17:43:18.046290 Epoch [046/050], Step [0010/0037], Gen Loss: 0.3729
2024-07-24 17:43:20.084716 Epoch [046/050], Step [0020/0037], Gen Loss: 0.3861
2024-07-24 17:43:22.042097 Epoch [046/050], Step [0030/0037], Gen Loss: 0.3774
2024-07-24 17:43:23.408538 Epoch [046/050], Step [0037/0037], Gen Loss: 0.3737
Generator Learning Rate: 2.5000000000000004e-07
2024-07-24 17:43:25.838108 Epoch [047/050], Step [0010/0037], Gen Loss: 0.3399
2024-07-24 17:43:27.800332 Epoch [047/050], Step [0020/0037], Gen Loss: 0.3369
2024-07-24 17:43:29.755122 Epoch [047/050], Step [0030/0037], Gen Loss: 0.3545
2024-07-24 17:43:31.116875 Epoch [047/050], Step [0037/0037], Gen Loss: 0.3580
Generator Learning Rate: 2.5000000000000004e-07
2024-07-24 17:43:33.572963 Epoch [048/050], Step [0010/0037], Gen Loss: 0.3370
2024-07-24 17:43:35.530749 Epoch [048/050], Step [0020/0037], Gen Loss: 0.3699
2024-07-24 17:43:37.481525 Epoch [048/050], Step [0030/0037], Gen Loss: 0.3674
2024-07-24 17:43:38.839377 Epoch [048/050], Step [0037/0037], Gen Loss: 0.3688
Generator Learning Rate: 2.5000000000000004e-07
2024-07-24 17:43:41.311090 Epoch [049/050], Step [0010/0037], Gen Loss: 0.3816
2024-07-24 17:43:43.269642 Epoch [049/050], Step [0020/0037], Gen Loss: 0.3655
2024-07-24 17:43:45.223393 Epoch [049/050], Step [0030/0037], Gen Loss: 0.3722
2024-07-24 17:43:46.582004 Epoch [049/050], Step [0037/0037], Gen Loss: 0.3676
Generator Learning Rate: 2.5000000000000004e-07
2024-07-24 17:43:49.026610 Epoch [050/050], Step [0010/0037], Gen Loss: 0.3667
2024-07-24 17:43:50.986244 Epoch [050/050], Step [0020/0037], Gen Loss: 0.3784
2024-07-24 17:43:52.938550 Epoch [050/050], Step [0030/0037], Gen Loss: 0.3727
2024-07-24 17:43:54.291999 Epoch [050/050], Step [0037/0037], Gen Loss: 0.3779

JOB STATISTICS
==============
Job ID: 7148689
Cluster: snellius
User/Group: scur2320/scur2320
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 00:11:42
CPU Efficiency: 9.47% of 02:03:36 core-walltime
Job Wall-clock time: 00:06:52
Memory Utilized: 2.70 GB
Memory Efficiency: 2.25% of 120.00 GB
