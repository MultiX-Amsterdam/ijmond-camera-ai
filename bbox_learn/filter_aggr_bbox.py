"""
This script does the following:
- Filter the dataset by specific labels.
- Compute the final bounding box.
- Save the image as .npy format.
"""
from util.util import (
    load_json,
    save_json,
    draw_bbox_on_image,
    convert_images_to_npy
)
from collections import defaultdict


def filter_by_label(metadata):
    """Filter the dataset by specific labels and compute the final bounding box."""
    filtered_metadata = []
    for v in metadata:
        bbox, state, debug_bbox_list = compute_box(v)
        if bbox is not None:
            d = {
                "id": v["id"],
                "state": state,
                "bbox": bbox,
                "debug_bbox_list": debug_bbox_list
            }
            filtered_metadata.append(d)
    return filtered_metadata


def compute_box(v):
    """Compute the bounding boxes based on the metadata."""
    # Get the box that is generated by the pretrained AI model
    h = v["h_image"]
    w = v["w_image"]
    ai_bbox = {
        "x_bbox": v["x_bbox"],
        "y_bbox": v["y_bbox"],
        "w_bbox": v["w_bbox"],
        "h_bbox": v["h_bbox"],
        "h_image": h,
        "w_image": w,
        "color": (0, 0, 255)
    }

    # Computer the final bounding box based on the label state
    label_state_admin = v["label_state_admin"]
    label_state = v["label_state"]
    if label_state_admin in [16, 17, 18]:
        if label_state_admin == 16:
            # This means the box is good, so we use the AI-generated box
            return ai_bbox, label_state_admin, None
        elif label_state_admin == 17:
            # This means that the box needs editing, so we use the adjusted box with the latest timestamp
            adjusted_bbox_list = v["feedback_filtered"]
            bbox = adjusted_bbox_list[0]
            for b in adjusted_bbox_list[1:]:
                # Check the dataset README for more information about the feedback codes
                if b["time"] > bbox["time"] and b["feedback_code"] == 17:
                    bbox = b
            bbox = {
                "x_bbox": bbox["x_bbox"],
                "y_bbox": bbox["y_bbox"],
                "w_bbox": bbox["w_bbox"],
                "h_bbox": bbox["h_bbox"],
                "h_image": h,
                "w_image": w
            }
            return bbox, label_state_admin, [ai_bbox]
        elif label_state_admin == 18:
            # This means that the box should be removed
            # We use these as negative examples to train the model
            return -1, label_state_admin, [ai_bbox]
    elif label_state in [13, 4, 15, 10, 3, 9, 11, 5, 12, 14]:
        # Explaination of states:
        # 0 : One person checked the box; the box is good (or there was no box, and the person agrees)
        # 1 : One person checked the box; the person edited the box
        # 2 : One person checked the box; the person removed the box due to no smoke (or there was no box, and the person added a box due to smoke)
        if label_state in [13, 4, 10]:
            # State 13 means: three people checked the box; they give state 1, 2, and 1
            # State 4 means: two people checked the box; they both edited the box (both gives state 1)
            # State 10 means: three people checked the box; they give state 0, 1, and 1
            # In this case, we need to get the two boxes with state 1, and compute the intersection
            adjusted_bbox_list = v["feedback_filtered"]
            # Get the two latest boxes with state 1 with feedback code 1
            boxes = [b for b in adjusted_bbox_list if b["feedback_code"] == 1]
            if len(boxes) < 2:
                return None, None, None
            # Sort by timestamp and take the two latest boxes
            boxes = sorted(boxes, key=lambda x: x["time"], reverse=True)[:2]
            # Compute the intersection of the two boxes
            bbox0 = {
                "x_bbox": boxes[0]["x_bbox"],
                "y_bbox": boxes[0]["y_bbox"],
                "w_bbox": boxes[0]["w_bbox"],
                "h_bbox": boxes[0]["h_bbox"],
                "h_image": h,
                "w_image": w,
                "color": (0, 255, 0)
            }
            bbox1 = {
                "x_bbox": boxes[1]["x_bbox"],
                "y_bbox": boxes[1]["y_bbox"],
                "w_bbox": boxes[1]["w_bbox"],
                "h_bbox": boxes[1]["h_bbox"],
                "h_image": h,
                "w_image": w,
                "color": (0, 255, 0)
            }
            bbox = intersection(bbox0, bbox1)
            if bbox is None:
                return None, None, None
            if label_state == 10:
                # If label_state is 10, we need to compute the intersection with the AI-generated box
                bbox = intersection(bbox, ai_bbox)
                if bbox is None:
                    return None, None, None
            return bbox, label_state, [bbox0, bbox1, ai_bbox]
        elif label_state in [15, 9]:
            # State 15 means: three people checked the box; they give state 0, 1, and 2
            # In this case, we need to get the box with state 1, and compute the intersection with the AI-generated box
            adjusted_bbox_list = v["feedback_filtered"]
            # Get the box with state 1 with feedback code 1
            boxes = [b for b in adjusted_bbox_list if b["feedback_code"] == 1]
            if len(boxes) < 1:
                return None, None, None
            # Sort by timestamp and take the latest box
            box = sorted(boxes, key=lambda x: x["time"], reverse=True)[0]
            bbox0 = {
                "x_bbox": box["x_bbox"],
                "y_bbox": box["y_bbox"],
                "w_bbox": box["w_bbox"],
                "h_bbox": box["h_bbox"],
                "h_image": h,
                "w_image": w,
                "color": (0, 255, 0)
            }
            bbox = intersection(bbox0, ai_bbox)
            if bbox is None:
                return None, None, None
            return bbox, label_state, [bbox0, ai_bbox]
        elif label_state in [3, 11, 9]:
            # State 3 means: two people checked the box; they agree that the box is good
            # State 11 means: three people checked the box; they give state 0, 2, and 0
            # State 9 means: three people checked the box; they give state 0, 1, and 0
            # In this case, we use the AI-generated box
            return ai_bbox, label_state, None
        elif label_state in [5, 12, 14]:
            # This means that the box should be removed
            # We use these as negative examples to train the model
            return -1, label_state, [ai_bbox]

    # If we reach here, it means we have an invalid bounding box
    return None, None, None


def intersection(bbox0, bbox1, pixel_threshold=10, iou_threshold=0.5):
    """Compute the intersection of two bounding boxes."""
    x1 = max(bbox0["x_bbox"], bbox1["x_bbox"])
    y1 = max(bbox0["y_bbox"], bbox1["y_bbox"])
    x2 = min(bbox0["x_bbox"] + bbox0["w_bbox"], bbox1["x_bbox"] + bbox1["w_bbox"])
    y2 = min(bbox0["y_bbox"] + bbox0["h_bbox"], bbox1["y_bbox"] + bbox1["h_bbox"])
    w = x2 - x1
    h = y2 - y1
    # We do not want to return a box that is too small
    if w <= pixel_threshold or h <= pixel_threshold:
        return None
    # We do not want a box that with an IoU that is too small
    area0 = bbox0["w_bbox"] * bbox0["h_bbox"]
    area1 = bbox1["w_bbox"] * bbox1["h_bbox"]
    intersection_area = w * h
    union_area = area0 + area1 - intersection_area
    if union_area == 0 or (intersection_area / union_area) < iou_threshold:
        return None
    return {
        "x_bbox": x1,
        "y_bbox": y1,
        "w_bbox": w,
        "h_bbox": h,
        "h_image": bbox0["h_image"],
        "w_image": bbox0["w_image"]
    }


if __name__ == "__main__":
    metadata_path = "dataset/ijmond_bbox/bbox_labels_26_may_2025.json"
    metadata = load_json(metadata_path)["data"]
    print("Before filtering...")
    print("Number of metadata entries:", len(metadata))
    print(metadata[0])

    # Filter the metadata by label
    print("=" * 50)
    filtered_metadata = filter_by_label(metadata)
    print("After filtering...")
    print("Number of metadata entries:", len(filtered_metadata))
    print(filtered_metadata[0])

    # Save the filtered metadata
    print("=" * 50)
    filtered_metadata_path = "dataset/ijmond_bbox/filtered_bbox_labels_26_may_2025.json"
    filtered_metadata_copy = []
    # Only keep the "id" and "bbox" fields
    for record in filtered_metadata:
        filtered_record = {
            "id": record["id"],
            "bbox": record["bbox"]
        }
        filtered_metadata_copy.append(filtered_record)
    save_json(filtered_metadata_copy, filtered_metadata_path)
    print(f"Filtered metadata saved to {filtered_metadata_path}.")

    # Index the filtered metadata by id and group by state
    print("=" * 50)
    filtered_metadata_by_state = defaultdict(list)
    for record in filtered_metadata:
        filtered_metadata_by_state[record["state"]].append(record)
    filtered_metadata_by_state = dict(filtered_metadata_by_state)

    # For each box, get the image and overlay the bounding box
    # Also convert the image to .npy format and save it
    print("Drawing bounding boxes on images and saving overlays...")
    print("=" * 50)
    for state, records in filtered_metadata_by_state.items():
        for record in records:
            img_id = record["id"]
            img_path = f"dataset/ijmond_bbox/img/{img_id}.png"
            save_path = f"dataset/ijmond_bbox/debug/state_{state}/{img_id}.png"
            bbox_list = []
            # Draw debug bounding boxes if available
            if record["debug_bbox_list"]:
                for debug_bbox in record["debug_bbox_list"]:
                    bbox_list.append(debug_bbox)
            if record["bbox"] is not -1:
                # -1 means the box should be removed, so we skip it, but we still need to keep the record
                # Add the final bounding box
                bbox_list.append(record["bbox"])
            draw_bbox_on_image(img_path, save_path, bbox_list)
            convert_images_to_npy(img_path, f"dataset/ijmond_bbox/img_npy/{img_id}.npy");
            print(f"Overlay saved to {save_path}")

    # Print the total number of records
    # , the records per state
    # , and the records for negative examples (state 5, 12, 14, and 18)
    print("=" * 50)
    print("Total number of records after filtering:", len(filtered_metadata))
    print("Number of records per state:")
    for state, records in filtered_metadata_by_state.items():
        print(f"State {state}: {len(records)} records")
    print("Number of negative examples (state 5, 12, 14, and 18):")
    negative_states = [5, 12, 14, 18]
    negative_count = sum(len(records) for state, records in filtered_metadata_by_state.items() if state in negative_states)
    print(f"Negative examples: {negative_count} records")
