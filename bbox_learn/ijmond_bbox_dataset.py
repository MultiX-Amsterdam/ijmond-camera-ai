import os
import torch
from torch.utils.data import Dataset
from torchvision import tv_tensors
import numpy as np
from util.util import (
    load_json,
    is_file_here
)


class IjmondBboxDataset(Dataset):
    def __init__(self, metadata_path=None, root_dir=None, transform=None):
        """
        metadata_path (string): the full path to the metadata json file (downloaded from IJmondCAM)
        root_dir (string): the root directory that stores images in .npy format
        transform (callable, optional): optional transform to be applied on an image
        """
        self.metadata = self.filter_by_label(load_json(metadata_path)["data"])
        self.root_dir = root_dir
        self.transform = transform

    def filter_by_label(self, metadata):
        """Filter the dataset by specific labels and compute the final bounding box."""
        filtered_metadata = []
        for v in metadata:
            bbox = self.compute_box(v)
            if bbox is not None:
                v["bbox"] = bbox
                filtered_metadata.append(v)
        return filtered_metadata

    def compute_box(self, v):
        """Compute the bounding boxes based on the metadata."""
        # Get the box that is generated by the pretrained AI model
        h = v["h_image"]
        w = v["w_image"]
        ai_bbox = tv_tensors.BoundingBoxes(
            torch.tensor([[v["x_bbox"], v["y_bbox"], v["w_bbox"], v["h_bbox"]]]),
            format=tv_tensors.BoundingBoxFormat.XYWH,
            canvas_size=(h, w)
        )

        # Computer the final bounding box based on the label state
        label_state_admin = v["label_state_admin"]
        label_state = v["label_state"]
        if label_state_admin in [16, 17]:
            if label_state_admin == 16:
                # This means the box is good, so we use the AI-generated box
                return ai_bbox
            elif label_state_admin == 17:
                # This means that the box needs editing, so we use the adjusted box with the latest timestamp
                adjusted_bbox_list = v["feedback_filtered"]
                bbox = adjusted_bbox_list[0]
                for b in adjusted_bbox_list[1:]:
                    # Check the dataset README for more information about the feedback codes
                    if b["timestamp"] > bbox["timestamp"] and b["feedback_code"] == 17:
                        bbox = b
                bbox = tv_tensors.BoundingBoxes(
                    torch.tensor([[bbox["x_bbox"], bbox["y_bbox"], bbox["w_bbox"], bbox["h_bbox"]]]),
                    format=tv_tensors.BoundingBoxFormat.XYWH,
                    canvas_size=(h, w)
                )
                return bbox
        elif label_state in [13, 4, 15, 10, 3, 6, 9, 11]:
            # Explaination of states:
            # 0 : One person checked the box; the box is good (or there was no box, and the person agrees)
            # 1 : One person checked the box; the person edited the box
            # 2 : One person checked the box; the person removed the box due to no smoke (or there was no box, and the person added a box due to smoke)
            if label_state == 13:
                # This means: three people checked the box; they give state 1, 2, and 1
                # In this case, we need to get the two boxes with state 1, and compute the intersection
                adjusted_bbox_list = v["feedback_filtered"]
                # Get the two latest boxes with state 1 with feedback code 1
                boxes = [b for b in adjusted_bbox_list if b["feedback_code"] == 1]
                if len(boxes) < 2:
                    return None
                # Sort by timestamp and take the two latest boxes
                boxes = sorted(boxes, key=lambda x: x["timestamp"], reverse=True)[:2]
                # Compute the intersection of the two boxes
                bbox = tv_tensors.BoundingBoxes(
                    torch.tensor([[boxes[0]["x_bbox"], boxes[0]["y_bbox"], boxes[0]["w_bbox"], boxes[0]["h_bbox"]]]),
                    format=tv_tensors.BoundingBoxFormat.XYWH,
                    canvas_size=(h, w)
                ).intersection(
                    tv_tensors.BoundingBoxes(
                        torch.tensor([[boxes[1]["x_bbox"], boxes[1]["y_bbox"], boxes[1]["w_bbox"], boxes[1]["h_bbox"]]]),
                        format=tv_tensors.BoundingBoxFormat.XYWH,
                        canvas_size=(h, w)
                    )
                )
                # If the intersection is empty, return None
                if bbox.is_empty():
                    return None

        # If we reach here, it means we have an invalid bounding box
        return None

    def __len__(self):
        return len(self.metadata)

    def __getitem__(self, idx):
        v = self.metadata[idx]

        file_path = os.path.join(self.root_dir, v["id"] + ".npy")
        if not is_file_here(file_path):
            raise ValueError("Cannot find file: %s" % (file_path))
        img = np.load(file_path).astype(np.uint8)

        # Transform image
        if self.transform:
            img = self.transform(img)

        return {"img": img, "bbox": bbox}
